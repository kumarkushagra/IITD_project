{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781bf244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 22 17:19:24 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   38C    P5              5W /   55W |    6302MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1967      G   /usr/lib/xorg/Xorg                      209MiB |\n",
      "|    0   N/A  N/A            2116      G   /usr/bin/gnome-shell                     61MiB |\n",
      "|    0   N/A  N/A            2718      G   ...rack-uuid=3190708988185955192        131MiB |\n",
      "|    0   N/A  N/A            2893      G   /usr/share/code/code                    122MiB |\n",
      "|    0   N/A  N/A            5175      G   /tmp/.mount_JoplinVSEDgU/joplin          47MiB |\n",
      "|    0   N/A  N/A           21401      C   ...anaconda3/envs/gpu/bin/python       5690MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 17:19:24.713883: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/vector/anaconda3/envs/gpu/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Num GPUs Available:  1\n",
      "GPU Details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))  \n",
    "print(\"GPU Details:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296585a",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92325612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33240 images belonging to 8 classes.\n",
      "Found 8306 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from load_dataset import load_dataset\n",
    "train_gen, val_gen, train_gen_class_indc = load_dataset(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a74a54",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030781f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ============================================================\n",
    "# SPATIAL CORE\n",
    "# - This is the DEPLOYMENT model (sliding window FCN)\n",
    "# - Input is dynamic: works on any image size\n",
    "# - Output is (h, w, num_classes)\n",
    "# ============================================================\n",
    "\n",
    "def build_spatial_core(num_classes=8):\n",
    "    inp = layers.Input(shape=(None, None, 3))\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # BACKBONE START\n",
    "    # Replace this block with ANY base model later\n",
    "    # Examples:\n",
    "    # - ResNet50 (include_top=False)\n",
    "    # - MobileNetV2\n",
    "    # - EfficientNet\n",
    "    #\n",
    "    # Rule:\n",
    "    #   base_model(inp)  -> feature map (h, w, c)\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\")(inp)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # BACKBONE END\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # FIXED WINDOW COLLAPSE\n",
    "    # This kernel size is chosen so that:\n",
    "    #   input 224x224 -> output 1x1\n",
    "    # Larger inputs -> sliding grid\n",
    "    # --------------------------------------------------------\n",
    "    x = layers.Conv2D(128, 26, activation=\"relu\")(x)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # CLASS CONFIDENCE PER WINDOW\n",
    "    # DO NOT put softmax here\n",
    "    # --------------------------------------------------------\n",
    "    out = layers.Conv2D(num_classes, 1)(x)   # (h, w, num_classes)\n",
    "\n",
    "    return models.Model(inp, out, name=\"spatial_core\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING MODEL\n",
    "# - This is ONLY for training\n",
    "# - Uses fixed input size because of ImageDataGenerator\n",
    "# - Collapses spatial output to match image-level labels\n",
    "# ============================================================\n",
    "\n",
    "def build_training_model(spatial_core, num_classes=8):\n",
    "    inp = layers.Input(shape=(224, 224, 3))   # fixed for generator\n",
    "\n",
    "    # spatial_core produces (1,1,num_classes) for 224x224\n",
    "    x = spatial_core(inp)\n",
    "\n",
    "    # Collapse spatial dims so loss sees (num_classes)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Image-level classification head\n",
    "    out = layers.Activation(\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inp, out, name=\"training_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aab528",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_core = build_spatial_core(num_classes=len(train_gen_class_indc))\n",
    "training_model = build_training_model(spatial_core, num_classes=len(train_gen_class_indc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73232469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=\"best_model.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.3,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring model fits on GPU\n",
    "history = training_model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch  = len(X_train) // batch_size,\n",
    "    validation_steps = len(X_val) // batch_size,\n",
    "    validation_data=val_gen,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
